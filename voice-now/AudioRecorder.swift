//
//  AudioRecorder.swift
//  voice-now
//
//  éŸ³é¢‘å½•åˆ¶ç®¡ç†
//

import AVFoundation
import Foundation
import Combine

class AudioRecorder: NSObject, ObservableObject {
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    
    @Published var isRecording = false
    @Published var errorMessage: String?
    
    var onAudioData: ((Data) -> Void)?
    
    override init() {
        super.init()
    }
    
    func requestPermission(completion: @escaping (Bool) -> Void) {
        AVCaptureDevice.requestAccess(for: .audio) { granted in
            DispatchQueue.main.async {
                completion(granted)
            }
        }
    }
    
    func startRecording() {
        guard !isRecording else { return }
        
        do {
            audioEngine = AVAudioEngine()
            guard let audioEngine = audioEngine else { return }
            
            inputNode = audioEngine.inputNode
            guard let inputNode = inputNode else { return }
            
            let recordingFormat = inputNode.outputFormat(forBus: 0)
            let sampleRate = ConfigManager.shared.sampleRate
            
            // åˆ›å»º 16kHz å•å£°é“ PCM æ ¼å¼
            guard let targetFormat = AVAudioFormat(
                commonFormat: .pcmFormatInt16,
                sampleRate: Double(sampleRate),
                channels: 1,
                interleaved: true
            ) else {
                errorMessage = "æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼"
                return
            }
            
            // åˆ›å»ºæ ¼å¼è½¬æ¢å™¨
            guard let converter = AVAudioConverter(from: recordingFormat, to: targetFormat) else {
                errorMessage = "æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨"
                return
            }
            
            inputNode.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { [weak self] buffer, _ in
                guard let self = self else { return }
                
                // è®¡ç®—è½¬æ¢åçš„å¸§æ•°ï¼ˆé‡‡æ ·ç‡è½¬æ¢æ¯”ä¾‹ï¼‰
                let ratio = targetFormat.sampleRate / recordingFormat.sampleRate
                let outputFrameCapacity = AVAudioFrameCount(Double(buffer.frameLength) * ratio)
                
                // åˆ›å»ºè½¬æ¢åçš„ç¼“å†²åŒº
                guard let convertedBuffer = AVAudioPCMBuffer(
                    pcmFormat: targetFormat,
                    frameCapacity: outputFrameCapacity
                ) else {
                    print("âŒ æ— æ³•åˆ›å»ºè½¬æ¢åçš„éŸ³é¢‘ç¼“å†²åŒº")
                    return
                }
                
                convertedBuffer.frameLength = outputFrameCapacity
                
                var error: NSError?
                var hasReturnedData = false  // æ ‡è®°æ˜¯å¦å·²è¿”å›æ•°æ®
                
                let status = converter.convert(to: convertedBuffer, error: &error) { inNumPackets, outStatus in
                    if !hasReturnedData {
                        outStatus.pointee = .haveData
                        hasReturnedData = true  // æ ‡è®°ä¸ºå·²è¿”å›
                        return buffer
                    } else {
                        outStatus.pointee = .noDataNow
                        return nil
                    }
                }
                
                if let error = error {
                    print("âŒ éŸ³é¢‘è½¬æ¢é”™è¯¯: \(error)")
                    return
                }
                
                if status == .error {
                    print("âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥")
                    return
                }
                
                // è½¬æ¢ä¸º Dataï¼ˆä½¿ç”¨å®é™…è½¬æ¢åçš„å¸§é•¿åº¦ï¼‰
                if let channelData = convertedBuffer.int16ChannelData {
                    let channelDataValue = channelData.pointee
                    let dataSize = Int(convertedBuffer.frameLength) * MemoryLayout<Int16>.size
                    let data = Data(bytes: channelDataValue, count: dataSize)
                    
                    // æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                    // print("ğŸµ éŸ³é¢‘æ•°æ®: \(buffer.frameLength) å¸§ -> \(convertedBuffer.frameLength) å¸§, \(data.count) å­—èŠ‚")
                    
                    self.onAudioData?(data)
                }
            }
            
            audioEngine.prepare()
            try audioEngine.start()
            
            DispatchQueue.main.async {
                self.isRecording = true
                self.errorMessage = nil
            }
            print("âœ… éŸ³é¢‘å½•åˆ¶å·²å¯åŠ¨")
            
        } catch {
            DispatchQueue.main.async {
                self.errorMessage = "å½•éŸ³å¯åŠ¨å¤±è´¥: \(error.localizedDescription)"
            }
            print("å½•éŸ³é”™è¯¯: \(error)")
        }
    }
    
    func stopRecording() {
        // ä½¿ç”¨ audioEngine ä½œä¸ºæ›´å¯é çš„æ£€æŸ¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        guard let engine = audioEngine else {
            DispatchQueue.main.async { [weak self] in
                self?.isRecording = false
            }
            return
        }
        
        inputNode?.removeTap(onBus: 0)
        engine.stop()
        audioEngine = nil
        inputNode = nil
        
        DispatchQueue.main.async { [weak self] in
            self?.isRecording = false
        }
        print("â¹ï¸ éŸ³é¢‘å½•åˆ¶å·²åœæ­¢")
    }
}

